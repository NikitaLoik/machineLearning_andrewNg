{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Univariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathToDataFile = 'ex1data1.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv(pathToDataFile, header = None)\n",
    "sampleSize, numVariables = dataFrame.shape\n",
    "print (\"sampleSize =\", sampleSize, \"numVariables =\", numVariables)\n",
    "print (dataFrame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xs = dataFrame.iloc[:, :1]\n",
    "Ys = dataFrame.iloc[:, 1:2]\n",
    "plt.plot(Xs, Ys, 'o')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Extraction and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getData(pathToDataFile):\n",
    "    data = np.loadtxt(pathToDataFile, delimiter = ',')\n",
    "    sampleSize, numVariables = data.shape\n",
    "#     matrix of variables X(n, k), where n is sampleSize, and k is numVariables, including the intercept\n",
    "    X = np.insert(data[:, :-1], 0, 1, axis=1)\n",
    "#     vector of response y(n, 1), where n is sampleSize\n",
    "    y = data[:, -1:]\n",
    "#     vector of coefficients beta(k, 1), where k is numVariables, including the intercept\n",
    "    beta = np.zeros((numVariables,1))\n",
    "    return beta, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beta, X, y = getData(pathToDataFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Computing Parameters Analytically\n",
    "**Coefficient Matrix** can be calculated as follows \n",
    "$$\\beta = (X^T\\cdot X)^{-1}\\cdot X^T\\cdot y$$\n",
    "\n",
    "**X** is a matrix of variables with a first column of dummy variables as intercept (column of ones).\n",
    "**y** is a vector of responses.\n",
    "$\\theta$ is a vector of coefficients in the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Computing Parameters Analytically\n",
    "def linearRegression_analytical(X, y):\n",
    "#     beta vector (2, 1), vector of coefficients\n",
    "    beta = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Computing Parameters Using Gradient Descent & Linear Algebra\n",
    "\n",
    "#### Vector Representation of the Regression Problem\n",
    "Variables matrix X:\n",
    "\\begin{equation}\n",
    "X =\n",
    "\\begin{vmatrix}\n",
    "x_{1,1} & \\ldots & x_{1,j} \\\\\n",
    "\\ldots & \\ldots & \\ldots \\\\\n",
    "x_{n,1} & \\ldots & x_{n,j}\\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "$$\n",
    "X = \\begin{vmatrix}\n",
    "x_{1,1} & \\ldots & x_{1,j} \\\\\n",
    "\\ldots & \\ldots & \\ldots \\\\\n",
    "x_{n,1} & \\ldots & x_{n,j}\\\\\n",
    "\\end{vmatrix}$$\n",
    "\n",
    "Variables marix X, after adding a column of ones as intercepts:\n",
    "\\begin{equation}\n",
    "X =\n",
    "\\begin{vmatrix}\n",
    "1 & x_{1,1} & \\ldots & x_{1,k} \\\\\n",
    "1 & \\ldots & \\ldots & \\ldots \\\\\n",
    "1 & x_{n,1}& \\ldots & x_{n,k}\\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Response vector Y:\n",
    "\\begin{equation}\n",
    "Y =\n",
    "\\begin{vmatrix}\n",
    "y_1\\\\\n",
    "\\ldots\\\\\n",
    "y_n\\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Coefficients vector $\\beta$:\n",
    "\\begin{equation}\n",
    "\\beta =\n",
    "\\begin{vmatrix}\n",
    "\\beta_1\\\\\n",
    "\\ldots\\\\\n",
    "\\beta_k\\\\\n",
    "\\end{vmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "**Hypothesis** $h_{\\beta}(X) =  X\\cdot\\beta$\n",
    "\n",
    "**Error** $e = (h_{\\beta}(X) - y)$\n",
    "\n",
    "**Cost Function** $J = \\frac{1}{2n}{\\sum(h_{\\beta} - y)^2}$\n",
    "\n",
    "**Gradient** $\\frac{\\partial J}{\\partial \\beta} = \\frac{1}{n}X^{T}\\cdot e$<br\\>\n",
    "\n",
    "In the code $\\frac{\\partial J}{\\partial \\beta}$ is denoted symply as **g**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hypothesis(beta, X):\n",
    "#     return hypothesis vector h(n, 1), where n is sampleSize\n",
    "    return np.dot(X, beta)\n",
    "\n",
    "def costFunction(beta, X, y):\n",
    "    sampleSize, numVariables = X.shape\n",
    "#     hypothesis vector h(n, 1)\n",
    "    h = hypothesis(beta, X)\n",
    "#     cost scalar J(1, 1)\n",
    "    J = np.sum((y-h)**2)/(2*sampleSize)\n",
    "#     similarly, cost J can be calculated using dot-product\n",
    "#     J = np.dot((y-h).T, y-h)/(2*sampleSize)\n",
    "#     technically, the result is an array (1,1) rather than a float\n",
    "    return J\n",
    "\n",
    "def gradientDescent(beta, X, y, alpha, iterations):\n",
    "    sampleSize, numVariables = X.shape\n",
    "    J_history = []\n",
    "    for i in range(iterations):\n",
    "#         hypothesis vector h(n, 1)\n",
    "        h = hypothesis(beta, X)\n",
    "#         error vector e(n, 1)\n",
    "        e = h - y\n",
    "#         cost scalar J\n",
    "        J = costFunction(beta, X, y)\n",
    "#         gradient vector g(k, 1)\n",
    "        g = np.dot(X.T, e)/(sampleSize)\n",
    "#         updated beta vector beta(k, 1)\n",
    "        beta = beta - alpha*g\n",
    "#         updated J_history\n",
    "        J_history += [J] \n",
    "    return beta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Results Visulisation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotRegression(beta, X, y):  \n",
    "#     yFit = betaFit[0][0] + betaFit[1][0]*X[:,1:]\n",
    "    yFit = np.dot(X,betaFit)\n",
    "    \n",
    "    MSE = np.sum((y - yFit)**2)/y.shape[0]\n",
    "    \n",
    "    plt.plot(X[:,1:], y, 'o', X[:,1:], yFit, '-')\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    print (\"β_0:\", betaFit[0][0],\n",
    "           \"\\nβ_1:\", betaFit[1][0],\n",
    "           \"\\nRegression: Y =\", '{:10.2f}'.format(betaFit[0][0]), '+', '{:10.2f}'.format(betaFit[1][0]), \"X\"\n",
    "           \"\\nMSE =\",'{:10.2f}'.format(MSE))\n",
    "    return plt.show()\n",
    "\n",
    "def plotConvergence(J_history, iterations):\n",
    "    plt.plot(np.arange(1, iterations + 1), J_history, '-')\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"J (cost)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1 Analytical Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betaFit = linearRegression_analytical(X, y)\n",
    "plotRegression(betaFit, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2 Gradient-Descent Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setting learning rate (alpha)\n",
    "alpha = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "betaFit = gradientDescent(beta, X, y, alpha, iterations)[0]\n",
    "plotRegression(betaFit, X, y)\n",
    "costVector = gradientDescent(beta, X, y, alpha, iterations)[1]\n",
    "plotConvergence(costVector, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iterations = 1000\n",
    "J = []\n",
    "for alpha in [0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1]:\n",
    "    beta, J_history = gradientDescent(beta, X, y, alpha, iterations)\n",
    "    J += [J_history[-1]]\n",
    "print (J)\n",
    "plt.plot([0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1], J, 'o-')\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.ylabel(\"J\")\n",
    "plt.show()\n",
    "#     print ('alpha =', str(alpha),'\\nJ =', J_history[-1])\n",
    "#     plotCostFunctionVSiterations(J_history, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Data Import & Manipulation Using Pandas\n",
    "https://codereview.stackexchange.com/questions/171144/gradient-descent-for-linear-regression-using-numpy-pandas<br\\>\n",
    "http://anwarruff.com/the-linear-regression-cost-function-in-matrix-form/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.1 Data Extraction and Transformation Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pandaData(pathToDataFile):\n",
    "    dataFrame = pd.read_csv(pathToDataFile, header = None, names = ['x1', 'y'])\n",
    "    dataFrame.insert(0, 'x0', 1)\n",
    "    nRows, nColumns = dataFrame.shape\n",
    "    X = dataFrame[['x0','x1']]\n",
    "    y = dataFrame[['y']]\n",
    "    beta = pd.DataFrame(np.zeros(X.shape[1]), columns = ['beta'])\n",
    "    return beta, X, y\n",
    "\n",
    "beta_pd, X_pd, y_pd = pandaData(pathToDataFile)\n",
    "\n",
    "print(X_pd.head())\n",
    "print(y_pd.head())\n",
    "print(beta_pd.head())\n",
    "print('Sample Size:', X_pd.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X_pd['x1'], y_pd, 'o', ms = 5)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plotRegression_pd(beta, X, y):\n",
    "#     yFit = betaFit[0][0] + betaFit[1][0]*X[:,1:]\n",
    "    yFit = np.dot(X,betaFit)\n",
    "    MSE = np.sum((y - yFit)**2)/y_pd.shape[0]\n",
    "\n",
    "    plt.plot(X['x1'], y, 'o', X['x1'], yFit, '-')\n",
    "    plt.xlabel(\"X\")\n",
    "    plt.ylabel(\"Y\")\n",
    "    print (\"β_0:\", betaFit[0][0],\n",
    "           \"\\nβ_1:\", betaFit[1][0],\n",
    "           \"\\nRegression: Y =\", '{:10.2f}'.format(betaFit[0][0]), '+', '{:10.2f}'.format(betaFit[1][0]), \"X\"\n",
    "           \"\\nMSE =\", '{:10.2f}'.format(MSE[0])\n",
    "          )\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.2 Analytical Approach Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "betaFit_pd = linearRegression_analytical(X_pd, y_pd)\n",
    "plotRegression_pd(betaFit_pd, X_pd, y_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3 Gradient-Descent Approach Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "iterations = 1000\n",
    "\n",
    "betaFit_pd = gradientDescent(beta_pd, X_pd, y_pd, alpha, iterations)\n",
    "plotRegression_pd(betaFit_pd[0], X_pd, y_pd)\n",
    "# costVector = gradientDescent(beta, X, y, alpha, iterations)[1]\n",
    "# plotConvergence(costVector, iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathToDataFile = 'ex1data2.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Extraction and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFrame = pd.read_csv(pathToDataFile, header = None, names = ['x1', 'x2', 'y'])\n",
    "dataFrame.insert(0, 'x0', 1)\n",
    "nRows, nColumns = dataFrame.shape\n",
    "X = dataFrame[['x0','x1', 'x2']]\n",
    "y = dataFrame[['y']]\n",
    "beta_pd = pd.DataFrame(np.zeros(X.shape[1]), columns = ['beta'])\n",
    "\n",
    "print(dataFrame.head())\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "print(beta_pd.head())\n",
    "print('Sample Size:', dataFrame.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
